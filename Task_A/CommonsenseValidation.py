# -*- coding: utf-8 -*-
"""taskA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18loZGXlPLnu4e5bfG1OeujnGURCT7WZ3

### Lets install all the dependencies first

First we are going to install **Hugging Face**
"""

pip install transformers

pip install -q ktrain

"""We now install dependencies for **NLTK**"""

import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

!git clone https://github.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation.git

"""### Now we will import libraries and Prepare the models"""

from nltk import pos_tag, word_tokenize
import tensorflow as tf
import tensorflow_hub as hub
import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
import keras
import math
import torch
import pickle
from keras.models import Model
import keras.backend as K
from sklearn.metrics import confusion_matrix,f1_score,classification_report
import matplotlib.pyplot as plt
from keras.callbacks import ModelCheckpoint
import itertools
from keras.models import load_model
from sklearn.utils import shuffle
from transformers import *
from transformers import BertTokenizer, TFBertModel, BertConfig
from transformers import OpenAIGPTTokenizer, OpenAIGPTLMHeadModel
import ktrain
from ktrain import text

"""**GPT** Model"""

modelGpt = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt')
modelGpt.eval()
tokenizerGpt = OpenAIGPTTokenizer.from_pretrained('openai-gpt')

"""**BERT** Model"""

bertTokenizer = BertTokenizer.from_pretrained("bert-large-uncased")
bertModel = TFBertForSequenceClassification.from_pretrained('bert-large-uncased',num_labels=2)

"""**DistilBert** Model"""

modelName = 'distilbert-base-uncased'

"""### Lets load the data

Train Data
"""

df = pd.read_csv ('SemEval2020-Task4-Commonsense-Validation-and-Explanation/''ALL data''/''Training  Data''/subtaskA_data_all.csv', header = None)
trainData =  df.to_numpy()
df = pd.read_csv ('SemEval2020-Task4-Commonsense-Validation-and-Explanation/''ALL data''/''Training  Data''/subtaskA_answers_all.csv', header = None)
trainLabels =  df.to_numpy()

"""Validation Data"""

df = pd.read_csv ('SemEval2020-Task4-Commonsense-Validation-and-Explanation/''ALL data''/''Dev Data''/subtaskA_dev_data.csv', header = None)
valData =  df.to_numpy()
df = pd.read_csv ('SemEval2020-Task4-Commonsense-Validation-and-Explanation/''ALL data''/''Dev Data''/subtaskA_gold_answers.csv', header = None)
valLabels =  df.to_numpy()

"""Test Data"""

df = pd.read_csv ('SemEval2020-Task4-Commonsense-Validation-and-Explanation/''ALL data''/''Test Data''/subtaskA_test_data.csv', header = None)
testData =  df.to_numpy()
df = pd.read_csv ('SemEval2020-Task4-Commonsense-Validation-and-Explanation/''ALL data''/''Test Data''/subtaskA_gold_answers.csv', header = None)
testLabels =  df.to_numpy()

"""Getting train data ready"""

Labels = []
for i in range(len(trainLabels)):
  if trainLabels[i][1] == 0:
    Labels.append(0)
    Labels.append(1)
  else:
    Labels.append(1)
    Labels.append(0)
sentenceId = [i[0] for i in trainData[1:]]
sentenceZero = [i[1] for i in trainData[1:]]
sentenceOne = [i[2] for i in trainData[1:]]
sentenceTrain = []
for i in range(len(sentenceZero)):
  sentenceTrain.append(sentenceZero[i])
  sentenceTrain.append(sentenceOne[i])
# print('ID\tSentence\tLabels')
sentId=[]
for i in range(len(sentenceId)):
  sentId.append(sentenceId[i])
  sentId.append(sentenceId[i])

"""Getting validation data ready"""

devLabels = []
for i in range(len(valLabels)):
  if valLabels[i][1] == 0:
    devLabels.append(0)
    devLabels.append(1)
  else:
    devLabels.append(1)
    devLabels.append(0)

devSentenceId = [i[0] for i in valData[1:]]
devSentenceZero = [i[1] for i in valData[1:]]
devSentenceOne = [i[2] for i in valData[1:]]
devSentences = []
for i in range(len(devSentenceZero)):
  devSentences.append(devSentenceZero[i])
  devSentences.append(devSentenceOne[i])

devSentId=[]
for i in range(len(devSentenceId)):
  devSentId.append(devSentenceId[i])
  devSentId.append(devSentenceId[i])

"""Getting test data ready"""

testLabel = []
for i in range(len(testLabels)):
  if testLabels[i][1] == 0:
    testLabel.append(0)
    testLabel.append(1)
  else:
    testLabel.append(1)
    testLabel.append(0)

testSentenceId = [i[0] for i in testData[1:]]
testSentenceZero = [i[1] for i in testData[1:]]
testSentenceOne = [i[2] for i in testData[1:]]
testSentences = []
for i in range(len(testSentenceZero)):
  testSentences.append(testSentenceZero[i])
  testSentences.append(testSentenceOne[i])

testSentId=[]
for i in range(len(testSentenceId)):
  testSentId.append(testSentenceId[i])
  testSentId.append(testSentenceId[i])

"""###**GPT**
As GPT is Pretrained we don't need to train out data we can get the preplexity and compare the values of both sentences and the one with higher score will be against common sense
"""

def perpScore(sentence):
    tokenizeInput = tokenizerGpt.tokenize(sentence)
    tensorInput = torch.tensor([tokenizerGpt.convert_tokens_to_ids(tokenizeInput)])
    loss = modelGpt(tensorInput, labels=tensorInput)
    return math.exp(loss[0])
predGpt = []
for i in range(len(testSentenceId)):
  sent = [testSentenceZero[i],testSentenceOne[i]]
  score = [perpScore(i) for i in sent]
  if score[1]>score[0]:
    predGpt.append(1)
  else:
    predGpt.append(0)

"""GPT Accuracy"""

correctGpt = 0
for i in range(len(predGpt)):
  if predGpt[i] == testLabels[i][1]: correctGpt +=1
print('GPT Accuracy:=>',(correctGpt/len(testSentenceId))*100,'%')

"""###**BERT**

Convert Sentences into Input IDs
"""

trainInputIds=[]
trainAttentionMasks=[]

for sent in sentenceTrain:
    bertInput=bertTokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)
    trainInputIds.append(bertInput['input_ids'])
    trainAttentionMasks.append(bertInput['attention_mask'])

trainInputIds=np.asarray(trainInputIds)
trainAttentionMasks=np.array(trainAttentionMasks)
train_labels=np.array(Labels)
# trainLabelList=np.array(labelList)

valInputIds=[]
valAttentionMasks=[]

for sent in devSentences:
    bertInput=bertTokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)
    valInputIds.append(bertInput['input_ids'])
    valAttentionMasks.append(bertInput['attention_mask'])

valInputIds=np.asarray(valInputIds)
valAttentionMasks=np.array(valAttentionMasks)
val_labels=np.array(devLabels)

testinputIds=[]
testattentionMasks=[]

for sent in testSentences:
    bertInput=bertTokenizer.encode_plus(sent,add_special_tokens = True,max_length =32,pad_to_max_length = True,return_attention_mask = True)
    testinputIds.append(bertInput['input_ids'])
    testattentionMasks.append(bertInput['attention_mask'])

testinputIds=np.asarray(testinputIds)
testattentionMasks=np.array(testattentionMasks)
testabels=np.array(testLabels)

trainIInp = trainInputIds
valIInp = valInputIds
trainLLabel = train_labels
valLLabel = val_labels
trainMMask = trainAttentionMasks
valMMask = valAttentionMasks


print('Train inp shape {} Val input shape {}\nTrain label shape {} Val label shape {}\nTrain attention mask shape {} Val attention mask shape {}'.format(trainIInp.shape,valIInp.shape,trainLLabel.shape,valLLabel.shape,trainMMask.shape,valMMask.shape))

"""Set Parameteres"""

print('\nBert Model :=>',bertModel.summary())

loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')
optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)

bertModel.compile(loss=loss,optimizer=optimizer,metrics=[metric])

"""Training"""

history=bertModel.fit([trainIInp,trainMMask],trainLLabel,batch_size=32,epochs=8,validation_data=([valIInp,valMMask],valLLabel))

"""Get predictions"""

bertPreds = bertModel.predict([testinputIds,testattentionMasks])
bertPredLabels = bertPreds[0].argmax(axis=1)
bertPred = []
i=0
while i<len(bertPredLabels):
  if bertPredLabels[i] == 0:
    bertPred.append(0)
    i += 2
  else:
    bertPred.append(1)
    i += 2
print('Classification Report')
print(classification_report(testLabel,bertPredLabels))

"""###*DistilBert**"""

dbTrainLabels = np.array(Labels)
dbValLabels = np.array(devLabels)

print('size of training set: %s' % (len(sentenceTrain)))
print('size of validation set: %s' % (len(devSentences)))
print('classes: %s' % (np.unique(Labels)))

x_train = sentenceTrain
y_train = dbTrainLabels
x_test = devSentences
y_test = dbValLabels

"""Prepare Model and parameter"""

t = text.Transformer(modelName, maxlen=500, classes=np.unique(Labels))
trn = t.preprocess_train(x_train, y_train)
val = t.preprocess_test(x_test, y_test)
model = t.get_classifier()
learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)

"""Training"""

learner.fit_onecycle(5e-5, 4)

"""Predictions"""

predictor = ktrain.get_predictor(learner.model, preproc=t)

dbPreds = []
i = 0
while i <len(testSentences):
  x1 = predictor.predict_proba(testSentences[i])
  x2 = predictor.predict_proba(testSentences[i+1])
  if x1[1]>x2[1] and x2[0]>x1[0]:
    dbPreds.append(1)
  else:
    dbPreds.append(0)
  i += 2

"""Getting labels with majority voting"""

output = []
for i in range(len(testSentenceId)):
  if dbPreds[i] == bertPred[i] == predGpt[i]:
    output.append([testSentenceId[i],dbPreds[i]])

  elif dbPreds[i] == bertPred[i] and bertPred[i] != predGpt[i]:
    output.append([testSentenceId[i],dbPreds[i]])
  
  elif dbPreds[i] == predGpt[i] and dbPreds[i] != bertPred[i]:
    output.append([testSentenceId[i],dbPreds[i]])

  elif predGpt[i] == bertPred[i] and dbPreds[i] != predGpt[i]:
    output.append([testSentenceId[i],bertPred[i]])

"""###Accuracy for Bert and Distil Bert and all three combined"""

df = pd.read_csv (r'SemEval2020-Task4-Commonsense-Validation-and-Explanation/''ALL data''/''Test Data''/subtaskA_gold_answers.csv', header = None)
testl =  df.to_numpy()

A = 0
for i in range(1000):
  if dbPreds[i] == testl[i][1]:
    A+=1
print('DistilBert Accuracy:=>',A/1000*100,'%')

B = 0
for i in range(1000):
  if bertPred[i] == testl[i][1]:
    B+=1
print('Bert Accuracy:=>',B/1000*100,'%')

C = 0
for i in range(1000):
  if output[i][1] == testl[i][1]:
    C+=1

print('Overall Accuracy:=>',C/1000*100,'%')

"""Generate Output file"""

df = pd.DataFrame(output)
df.to_csv('sample_data/subtaskA_answers.csv', index=False, header=False)

from google.colab import files
files.download('sample_data/subtaskA_answers.csv')